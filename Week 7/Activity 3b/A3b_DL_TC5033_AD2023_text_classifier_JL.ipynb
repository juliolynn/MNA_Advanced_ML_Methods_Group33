{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d35d0e96",
   "metadata": {},
   "source": [
    "#**Maestría en Inteligencia Artificial Aplicada**\n",
    "##**Advanced Machine Learning Methods (Gpo 10)**\n",
    "###Tecnológico de Monterrey\n",
    "###Profesor Ph.D. José Antonio Cantoral Ceballos\n",
    "\n",
    "## **Activity 3a**\n",
    "\n",
    "### Text Classification using RNNs and AG_NEWS dataset in PyTorch\n",
    "\n",
    "##**Team 33**:\n",
    "\n",
    "### Humberto Lozano Cedillo A01363184\n",
    "### Julio Cesar Lynn Jimenez A01793660\n",
    "### Sarah Mendoza Medina A01215352\n",
    "### David Mireles Samaniego A01302935"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "940c6dbc",
   "metadata": {},
   "source": [
    "## TC 5033\n",
    "### Word Embeddings\n",
    "\n",
    "<br>\n",
    "\n",
    "#### Activity 3b: Text Classification using RNNs and AG_NEWS dataset in PyTorch\n",
    "<br>\n",
    "\n",
    "- Objective:\n",
    "    - Understand the basics of Recurrent Neural Networks (RNNs) and their application in text classification.\n",
    "    - Learn how to handle a real-world text dataset, AG_NEWS, in PyTorch.\n",
    "    - Gain hands-on experience in defining, training, and evaluating a text classification model in PyTorch.\n",
    "    \n",
    "<br>\n",
    "\n",
    "- Instructions:\n",
    "    - Data Preparation: Starter code will be provided that loads the AG_NEWS dataset and prepares it for training. Do not modify this part. However, you should be sure to understand it, and comment it, the use of markdown cells is suggested. \n",
    "\n",
    "    - Model Setup: A skeleton code for the RNN model class will be provided. Complete this class and use it to instantiate your model.\n",
    "\n",
    "    - Implementing Accuracy Function: Write a function that takes model predictions and ground truth labels as input and returns the model's accuracy.\n",
    "\n",
    "    - Training Function: Implement a function that performs training on the given model using the AG_NEWS dataset. Your model should achieve an accuracy of at least 80% to get full marks for this part.\n",
    "\n",
    "    - Text Sampling: Write a function that takes a sample text as input and classifies it using your trained model.\n",
    "\n",
    "    - Confusion Matrix: Implement a function to display the confusion matrix for your model on the test data.\n",
    "\n",
    "    - Submission: Submit your completed Jupyter Notebook. Make sure to include a markdown cell at the beginning of the notebook that lists the names of all team members. Teams should consist of 3 to 4 members.\n",
    "    \n",
    "<br>\n",
    "\n",
    "- Evaluation Criteria:\n",
    "\n",
    "    - Correct setup of all the required libraries and modules (10%)\n",
    "    - Code Quality (30%): Your code should be well-organized, clearly commented, and easy to follow. Use also markdown cells for clarity. Comments should be given for all the provided code, this will help you understand its functionality.\n",
    "    \n",
    "   - Functionality (60%): \n",
    "        - All the functions should execute without errors and provide the expected outputs.\n",
    "        - RNN model class (20%)\n",
    "        - Accuracy fucntion (10%)\n",
    "        - Training function (10%)\n",
    "        - Sampling function (10%)\n",
    "        - Confucion matrix (10%)\n",
    "\n",
    "        - The model should achieve at least an 80% accuracy on the AG_NEWS test set for full marks in this criterion.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4de318da",
   "metadata": {},
   "source": [
    "Dataset\n",
    "\n",
    "https://pytorch.org/text/stable/datasets.html#text-classification\n",
    "\n",
    "https://paperswithcode.com/dataset/ag-news\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a9801f9",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "54394f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# conda install -c pytorch torchtext\n",
    "# conda install -c pytorch torchdata\n",
    "# conda install pytorch torchvision torchaudio cudatoolkit=10.2 -c pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "878b524f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following libraries are required for running the given code\n",
    "# Please feel free to add any libraries you consider adecuate to complete the assingment.\n",
    "import numpy as np\n",
    "#PyTorch libraries\n",
    "import torch\n",
    "from torchtext.datasets import AG_NEWS\n",
    "# Dataloader library\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.dataset import random_split\n",
    "# Libraries to prepare the data\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "from torchtext.data.functional import to_map_style_dataset\n",
    "# neural layers\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "# These libraries are suggested to plot confusion matrix\n",
    "# you may use others\n",
    "import scikitplot as skplt\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "3bab55f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# Use GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d38956d",
   "metadata": {},
   "source": [
    "### Get the train and the test datasets and dataloaders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9c6b784",
   "metadata": {},
   "source": [
    "Classes:\n",
    "\n",
    "* 1 - World\n",
    "\n",
    "* 2 - Sports\n",
    "\n",
    "* 3 - Business\n",
    "\n",
    "* 4 - Sci/Tech\n",
    "\n",
    "We will convert them to:\n",
    "\n",
    "* 0 - World\n",
    "\n",
    "* 1 - Sports\n",
    "\n",
    "* 2 - Business\n",
    "\n",
    "* 3 - Sci/Tech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "49fbed19",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, test_dataset = AG_NEWS()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ShardingFilterIterDataPipe"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "e017f28c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, test_dataset = to_map_style_dataset(train_dataset), to_map_style_dataset(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "9c372eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the tokeniser\n",
    "# tokeniser object\n",
    "tokeniser = get_tokenizer('basic_english')\n",
    "\n",
    "def yield_tokens(data):\n",
    "    for _, text in data:\n",
    "        yield tokeniser(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "794d0375",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the vocabulary\n",
    "vocab = build_vocab_from_iterator(yield_tokens(train_dataset), specials=[\"<unk>\"])\n",
    "#set unknown token at position 0\n",
    "vocab.set_default_index(vocab[\"<unk>\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "b48268d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['welcome', 'to', 'te3007'] [3314, 4, 0]\n"
     ]
    }
   ],
   "source": [
    "#test tokens\n",
    "tokens = tokeniser('Welcome to TE3007')\n",
    "print(tokens, vocab(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "c8c8f6a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_TRAIN = int(len(train_dataset)*0.9)\n",
    "NUM_VAL = len(train_dataset) - NUM_TRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "8290895e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, val_dataset = random_split(train_dataset, [NUM_TRAIN, NUM_VAL])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "cbc75b54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108000 12000 7600\n"
     ]
    }
   ],
   "source": [
    "print(len(train_dataset), len(val_dataset), len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "5eb459c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels =  [\"World\", \"Sports\", \"Business\", \"Sci/Tech\"]\n",
    "max_tokens = 50\n",
    "BATCH_SIZE = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the text processing pipeline with the tokenizer and vocabulary. \n",
    "# The text and label pipelines will be used to process the raw data strings from the dataset iterators.\n",
    "text_pipeline = lambda x: vocab(tokeniser(x))\n",
    "label_pipeline = lambda x: int(x) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "ffdbf077",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function passed to the DataLoader to process a batch of data as indicated\n",
    "def collate_batch(batch):\n",
    "    # Get label and text\n",
    "    y, x = list(zip(*batch))\n",
    "    \n",
    "    # Create list with indices from tokeniser\n",
    "    x = [vocab(tokeniser(text)) for text in x]\n",
    "    x = [t + ([0]*(max_tokens - len(t))) if len(t) < max_tokens else t[:max_tokens] for t in x]\n",
    "\n",
    "    # Prepare the labels, by subtracting 1 to get them in the range 0-3\n",
    "    return torch.tensor(x, dtype=torch.int32), torch.tensor(y, dtype=torch.int32) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "0a55e6ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, collate_fn=collate_batch, shuffle = True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, collate_fn=collate_batch, shuffle = True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, collate_fn=collate_batch, shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47b98898",
   "metadata": {},
   "source": [
    "### Let us build our RNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "50f20793",
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_SIZE = 300\n",
    "NEURONS = BATCH_SIZE\n",
    "LAYERS = 2\n",
    "NUM_CLASSES = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "0f7f5621",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN_Model_1(nn.Module):\n",
    "    def __init__(self, embed_size, hidden, layers, num_classes):\n",
    "        super().__init__()\n",
    "        self.embedding_layer = nn.Embedding(num_embeddings=len(vocab), \n",
    "                                            embedding_dim=embed_size)\n",
    "        \n",
    "        self.rnn = nn.GRU(input_size= embed_size,\n",
    "                            hidden_size=hidden,\n",
    "                            num_layers=layers,\n",
    "                            batch_first=True,\n",
    "                            bidirectional=False # First train only one direction as a baseline   \n",
    "                           ) \n",
    "                        \n",
    "                        \n",
    "        \n",
    "        self.fc = nn.Linear(in_features=hidden, out_features=num_classes) \n",
    "      \n",
    "        \n",
    "    def forward(self, x):\n",
    "        embedded = self.embedding_layer(x)\n",
    "        y, h = self.rnn(embedded)\n",
    "        return self.fc(y[:,-1]) # Only use output for last timestep. The reason is because this is a classification problem.\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "2a42613f",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def accuracy(model, loader):\n",
    "    model.eval()\n",
    "    total_acc, total_count = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for idx, (xi, yi) in enumerate(loader):\n",
    "            xi = xi.to(device=device, dtype = torch.int32)\n",
    "            yi = yi.to(device=device, dtype = torch.int32)\n",
    "            \n",
    "            predicted_label = model(xi)\n",
    "            # loss = criterion(predicted_label, label)\n",
    "            total_acc += (predicted_label.argmax(1) == yi).sum().item()\n",
    "            total_count += yi.size(0)\n",
    "    return total_acc / total_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "87775b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 3\n",
    "lr = 0.001\n",
    "# instantiate model\n",
    "rnn_model = RNN_Model_1(EMBEDDING_SIZE, NEURONS, LAYERS, NUM_CLASSES)\n",
    "optimiser = torch.optim.Adam(rnn_model.parameters(), lr=lr)\n",
    "criterion = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "\n",
    "def train_epoch(model, dataloader, optimiser, epoch):\n",
    "    model.train()\n",
    "    total_acc, total_count = 0, 0\n",
    "    log_interval = 500\n",
    "    start_time = time.time()\n",
    "\n",
    "    for idx, (xi, yi) in enumerate(dataloader):\n",
    "        xi = xi.to(device=device, dtype = torch.int32)\n",
    "        yi = yi.to(device=device, dtype = torch.long) # Hast to be defined as long for the cross_entropy compatibility with target as class indices\n",
    "    \n",
    "        optimiser.zero_grad()\n",
    "        scores = model(xi)\n",
    "        _, pred = scores.max(dim=1)\n",
    "\n",
    "        cost = F.cross_entropy(input=scores, target=yi)\n",
    "        cost.backward()\n",
    "\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.1)\n",
    "        optimiser.step()\n",
    "        total_acc += (pred == yi).sum().item()\n",
    "        total_count += yi.size(0)\n",
    "        if idx % log_interval == 0 and idx > 0:\n",
    "            elapsed = time.time() - start_time\n",
    "            print(\n",
    "                \"| epoch {:3d} | {:5d}/{:5d} batches \"\n",
    "                \"| accuracy {:8.3f}\".format(\n",
    "                    epoch, idx, len(dataloader), total_acc / total_count\n",
    "                )\n",
    "            )\n",
    "            total_acc, total_count = 0, 0\n",
    "            start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimiser, epochs):\n",
    "    model = model.to(device)\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        epoch_start_time = time.time()\n",
    "        train_epoch(model, train_loader, optimiser, epoch)\n",
    "        accu_val = accuracy(model, val_loader)\n",
    "\n",
    "        print(\"-\" * 59)\n",
    "        print(\n",
    "            \"| end of epoch {:3d} | time: {:5.2f}s | \"\n",
    "            \"valid accuracy {:8.3f} \".format(\n",
    "                epoch, time.time() - epoch_start_time, accu_val\n",
    "            )\n",
    "        )\n",
    "        print(\"-\" * 59)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "aec12a1b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------\n",
      "| end of epoch   1 | time: 28.18s | valid accuracy    0.895 \n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   2 | time: 26.55s | valid accuracy    0.915 \n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   3 | time: 28.79s | valid accuracy    0.915 \n",
      "-----------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "train(rnn_model, optimiser=optimiser,  epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "7a3ef175",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9139\n"
     ]
    }
   ],
   "source": [
    "print(f'{accuracy(rnn_model, test_loader):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "ag_news_label = {1: \"World\",\n",
    "                 2: \"Sports\",\n",
    "                 3: \"Business\",\n",
    "                 4: \"Sci/Tec\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, text):\n",
    "    model.eval()\n",
    "    x = [vocab(tokeniser(text))]\n",
    "    x = [t + ([0]*(max_tokens - len(t))) if len(t) < max_tokens else t[:max_tokens] for t in x]\n",
    "    xi = torch.tensor(x, dtype=torch.int32, device=device)\n",
    "\n",
    "    with torch.no_grad():   \n",
    "        predicted_label = model(xi)\n",
    "        return predicted_label.argmax(1).item() + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "ed30693d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_text(model, loader):\n",
    "    model = model.to(device)\n",
    "    dataset = loader.dataset\n",
    "\n",
    "    rnd_sample_idx = np.random.randint(len(dataset))\n",
    "    (label, text) = dataset[rnd_sample_idx]\n",
    "    print((ag_news_label[label], text))\n",
    "\n",
    "    pred = predict(model, text)\n",
    "    print(f'Predicted: {ag_news_label[pred]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "534f0220",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Business', 'SEC Probes United Rentals, Shares Drop  CHICAGO (Reuters) - U.S. securities regulators are  investigating United Rentals Inc. &lt;A HREF=\"http://www.investor.reuters.com/FullQuote.aspx?ticker=URI.N target=/stocks/quickinfo/fullquote\"&gt;URI.N&lt;/A&gt; and have subpoenaed  some accounting records, the company said on Monday, sending  its shares down 21.5 percent.')\n",
      "Predicted: Business\n"
     ]
    }
   ],
   "source": [
    "sample_text(rnn_model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: World\n"
     ]
    }
   ],
   "source": [
    "ex_text_str = \"MEMPHIS, Tenn. – Four days ago, Jon Rahm was \\\n",
    "    enduring the season’s worst weather conditions on Sunday at The \\\n",
    "    Open on his way to a closing 75 at Royal Portrush, which \\\n",
    "    considering the wind and the rain was a respectable showing. \\\n",
    "    Thursday’s first round at the WGC-FedEx St. Jude Invitational \\\n",
    "    was another story. With temperatures in the mid-80s and hardly any \\\n",
    "    wind, the Spaniard was 13 strokes better in a flawless round. \\\n",
    "    Thanks to his best putting performance on the PGA Tour, Rahm \\\n",
    "    finished with an 8-under 62 for a three-stroke lead, which \\\n",
    "    was even more impressive considering he’d never played the \\\n",
    "    front nine at TPC Southwind.\"\n",
    "\n",
    "pred = predict(rnn_model, ex_text_str)\n",
    "print(f'Predicted: {ag_news_label[pred]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb38e093",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create confusion matrix\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d73f69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bidirectional RNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN_Model_2(nn.Module):\n",
    "    def __init__(self, embed_size, hidden, layers, num_classes):\n",
    "        super().__init__()\n",
    "        self.embedding_layer = nn.Embedding(num_embeddings=len(vocab), \n",
    "                                            embedding_dim=embed_size)\n",
    "        \n",
    "        self.rnn = nn.GRU(input_size= embed_size,\n",
    "                            hidden_size=hidden,\n",
    "                            num_layers=layers,\n",
    "                            batch_first=True,\n",
    "                            bidirectional=True # First train only one direction as a baseline   \n",
    "                           ) \n",
    "                        \n",
    "        self.fc = nn.Linear(in_features=hidden*2, out_features=num_classes) # Double the size of hidden neurons to account for the reverse pass\n",
    "        \n",
    "    def forward(self, x):\n",
    "        embedded = self.embedding_layer(x)\n",
    "        y, h = self.rnn(embedded)\n",
    "        return self.fc(y[:,-1]) # Only use output for last timestep. The reason is because this is a classification problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "5327e204",
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_SIZE = 300\n",
    "NEURONS = BATCH_SIZE\n",
    "LAYERS = 3\n",
    "NUM_CLASSES = 4\n",
    "\n",
    "epochs = 5\n",
    "lr = 0.001\n",
    "# instantiate model\n",
    "bidir_rnn_model = RNN_Model_2(EMBEDDING_SIZE, NEURONS, LAYERS, NUM_CLASSES)\n",
    "bidir_optimiser = torch.optim.Adam(bidir_rnn_model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "7bc921f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------\n",
      "| end of epoch   1 | time: 563.92s | valid accuracy    0.895 \n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   2 | time: 614.04s | valid accuracy    0.915 \n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   3 | time: 616.65s | valid accuracy    0.921 \n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   4 | time: 616.33s | valid accuracy    0.918 \n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   5 | time: 607.12s | valid accuracy    0.915 \n",
      "-----------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "train(bidir_rnn_model, optimiser=bidir_optimiser, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(bidir_rnn_model, \"bidir_rnn_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9121\n"
     ]
    }
   ],
   "source": [
    "print(f'{accuracy(bidir_rnn_model, test_loader):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Sci/Tec', 'Dell unveils holiday lineup, including new plasma TVs OCTOBER 15, 2004 (IDG NEWS SERVICE) - Dell Inc. took the wraps off its holiday lineup on Thursday, showing new printers, plasma televisions and music players that will soon be available through its Web site.')\n",
      "Predicted: Sci/Tec\n"
     ]
    }
   ],
   "source": [
    "sample_text(bidir_rnn_model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "ed62b0d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: Sports\n"
     ]
    }
   ],
   "source": [
    "ex_text_str = \"MEMPHIS, Tenn. – Four days ago, Jon Rahm was \\\n",
    "    enduring the season’s worst weather conditions on Sunday at The \\\n",
    "    Open on his way to a closing 75 at Royal Portrush, which \\\n",
    "    considering the wind and the rain was a respectable showing. \\\n",
    "    Thursday’s first round at the WGC-FedEx St. Jude Invitational \\\n",
    "    was another story. With temperatures in the mid-80s and hardly any \\\n",
    "    wind, the Spaniard was 13 strokes better in a flawless round. \\\n",
    "    Thanks to his best putting performance on the PGA Tour, Rahm \\\n",
    "    finished with an 8-under 62 for a three-stroke lead, which \\\n",
    "    was even more impressive considering he’d never played the \\\n",
    "    front nine at TPC Southwind.\"\n",
    "\n",
    "pred = predict(bidir_rnn_model, ex_text_str)\n",
    "print(f'Predicted: {ag_news_label[pred]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c82cfd3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
